<!DOCTYPE HTML>
<html>
	<head>
		<title>Eyewear Computing in the Wild</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body class="homepage">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header-wrapper" class="wrapper">
					<div id="header">

						<!-- Logo -->
							<div id="logo">
								<h1><a href="index.html">Eyewear Computing in the Wild</a></h1>
								<p>Large Scale Dataset Recording During UbiComp</p>
								<h2>10th Sept. 13:00 - 17:00</h2>
							</div>

						<!-- Nav -->
							<nav id="nav">
								<ul>
									<li class="current"><a href="index.html">Home</a></li>
									<li><a href="#">Motivation</a></li>
									<li><a href="#details">Details</a></li>
									<li><a href="#requirements">Schedule</a></li>
									<li><a href="#orga">Contact</a></li>
								</ul>
							</nav>

					</div>
				</div>

			<!-- Intro -->
				<div id="intro-wrapper" class="wrapper style1">
					<div class="title">motivation</div>
					<section id="intro" class="container">
						<p class="style2">
Recording a Large Scale Dataset During UbiComp
						</p>
						<p class="style3" align="left">
						In this tutorial we present the Smart Eyewear toolchain consisting of smart glasses prototypes and a software platform for cognitive and social interaction assessments in the wild. We will present a series of, with several application cases and give a demonstration of activity recognition in real-time using eyewear. The platform is designed to work with J!NS MEME, smart EOG (electrooculography) enabled glasses. The user software is capable of data logging, posture tracking and recognition of several activities, such as talking, reading and blinking. In this tutorial organizers will walk through several applications and studies that the platform has been used for. Participants are able to reproduce results from these studies and are invited tocan design their own experimental setups. We will, furthermore, record a dataset during UbiComp actively involvingincluding the tutorial participants.
						</p>
					</section>
				</div>

				<div class="wrapper style3">
					<div class="title">Details</div>
					<div id="details" class="container">
						We will record a large scale dataset using smart eyewear during UbiComp
	11th-13th September 2019. The participants are asked to wear a J!NS MEME during the conference together with a smart phone we provide as well, recording their head and eye movements. Participants should also log which sessions they attend and a rating of the talks.

	Everybody participating in the recordings (and at least recording 2 days of usable data: over 8 hours throughout the day, and a couple of talk sessions), will get access to the full dataset together with ground truth label data and our toolchain to analyse EOG and movement data (includes advanced wavelet synchrony code, blink detection and an alertness-detection model based on EOG).
				</div>
					</div>
				</div>

				<div class="wrapper style2">
 					<div class="title">Schedule</div>
 					<div id="requirements" class="container">
					Sept. 10th 13:00 -17:00 preparations.

 					If participants want to take part in the date recording, they should not be wearing any glasses (contact lenses ok)
					as they will be asked to wear J!NS MEME during the 3 days of the conference.
 					</div>
 					</div>
 				</div>

			<!-- Main -->
				<div class="wrapper style3">
					<div class="title">Organizers</div>
					<div id="orga" class="container">
						<p> George Chernyshov, Keio Media Design</br>
							Shoya Ishimaru, DFKI, Kaiserslautern</br>
							Kai Kunze, Keio Media Design </br>
							Benjamin Tag, Melbourne University </br>
							Jamie Ward, Goldsmith University </br>
							Yuji Uema, J!NS Co. </br>
							Philipp Scholl, University Freiburg.
						</p>
					</div>
				</div>


			<!-- Footer -->
				<div id="footer-wrapper" class="wrapper">
					<div class="title">Contact</div>
					<div id="footer" class="container">
						<header class="style1">

							<p>
							eyewear2019 (at) eywear.pro
							</p>
						</header>
						<hr />

	</div>	</div>
		</div>

		<!-- Scripts -->

			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/skel-viewport.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
